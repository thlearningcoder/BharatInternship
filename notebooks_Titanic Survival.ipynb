{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Load the Titanic dataset (make sure you have the CSV file)\ndata = pd.read_csv('train.csv')\n\n# Define the features and target variable\nX = data.drop('Survived', axis=1)\ny = data['Survived']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define preprocessing steps for numerical and categorical data\nnumeric_features = ['Age', 'Fare']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_features = ['Sex', 'Pclass']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(drop='first'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Define the model\nmodel = Pipeline(steps=[('preprocessor', preprocessor),\n                        ('classifier', LogisticRegression(random_state=42))])\n\n# Fit the model to the training data\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"Classification Report:\")\nprint(classification_rep)\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk_B5IFykrsk",
        "outputId": "05ba5b24-a0d5-46b8-d9ea-4a7e1324f75b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 0.7988826815642458\n\nConfusion Matrix:\n\n[[90 15]\n\n [21 53]]\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n\n\n           0       0.81      0.86      0.83       105\n\n           1       0.78      0.72      0.75        74\n\n\n\n    accuracy                           0.80       179\n\n   macro avg       0.80      0.79      0.79       179\n\nweighted avg       0.80      0.80      0.80       179\n\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "print(data.columns)\n\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvk_AJawlbzX",
        "outputId": "712bc93b-8931-4890-b539-9ec31d5bc001"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n\n       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n\n      dtype='object')\n"
        }
      ]
    }
  ]
}